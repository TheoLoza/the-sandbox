from nltk.tokenize import sent_tokenize, word_tokenize
EXAMPLE_TEXT = "Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard! I am so blue I'm greener than purple. I stepped on a Corn Flake, now I'm a Cereal Killer. Everyday a grape licks a friendly cow. Look, a distraction! If your canoe is stuck in a tree with the headlights on, how many pancakes does it take to get to the moon?“

print(EXAMPLE_TEXT)
EXAMPLE_TEXT.split()

sent_tokenize(EXAMPLE_TEXT)
word_tokenize(EXAMPLE_TEXT)
